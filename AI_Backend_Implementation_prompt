# AI Chat Backend MVP - Implementation Prompt

## Project Context

You are implementing the backend for an AI chat feature in a React/Flask chat application called "LetsApp". The frontend is already implemented and expects specific API endpoints and response formats.

## MVP Requirements

### Core Functionality

Create a complete backend system that:

1. **Receives chat messages** from authenticated users
2. **Retrieves user's encrypted OpenAI API key** from database
3. **Calls OpenAI API** with the user's key to get AI response
4. **Stores both messages** (user + AI response) in database
5. **Returns formatted response** to frontend
6. **Handles all error cases** gracefully

### Technical Stack

- **Framework**: Flask with Blueprint architecture
- **Database**: MongoDB with existing collections
- **Authentication**: JWT tokens (already implemented)
- **Encryption**: Fernet symmetric encryption for API keys
- **AI Service**: OpenAI GPT-3.5-turbo API

## Database Schema

### Existing Collections

#### `users` collection:

```javascript
{
  _id: ObjectId,
  username: String,
  email: String,
  api_key: String (encrypted), // Add this field
  // ... other existing fields
}
```

#### `messages` collection:

```javascript
{
  _id: String,
  room_id: String,
  sender_id: String,
  content: String,
  timestamp: String (ISO format),
  message_type: String,
  is_ai_message: Boolean, // Add this field
  ai_model: String, // Add this field (optional)
  status: String
}
```

## API Endpoint Specifications

### 1. POST `/api/chat/ai/send`

**Purpose**: Send message to AI and get response

**Request Headers**:

```
Authorization: Bearer <jwt_token>
Content-Type: application/json
```

**Request Body**:

```json
{
  "message": "Hello, how are you?",
  "room_id": "ai_chat_6814c3373697dbe58e17e5c6",
  "user_id": "6814c3373697dbe58e17e5c6"
}
```

**Success Response (200)**:

```json
{
  "success": true,
  "user_message": {
    "id": "uuid-string",
    "content": "Hello, how are you?",
    "timestamp": "2025-08-28T10:30:00.000Z",
    "sender_id": "6814c3373697dbe58e17e5c6"
  },
  "ai_message": {
    "id": "uuid-string",
    "content": "Hello! I'm doing well, thank you for asking. How can I help you today?",
    "timestamp": "2025-08-28T10:30:01.000Z",
    "sender_id": "ai-assistant"
  }
}
```

**Error Responses**:

```json
// 400 - Missing API key
{
  "success": false,
  "error": "No API key configured or encryption not available"
}

// 400 - Invalid API key
{
  "success": false,
  "error": "Invalid API key. Please check your OpenAI API key in profile settings."
}

// 429 - Rate limit
{
  "success": false,
  "error": "API rate limit exceeded. Please try again later."
}

// 503 - Service unavailable
{
  "success": false,
  "error": "AI service temporarily unavailable. Please try again later."
}
```

### 2. GET `/api/chat/ai/history/<room_id>` (Optional)

**Purpose**: Get AI chat history for a room

**Success Response (200)**:

```json
{
  "success": true,
  "messages": [
    {
      "id": "uuid-string",
      "content": "Message content",
      "sender_id": "user_id or ai-assistant",
      "timestamp": "2025-08-28T10:30:00.000Z",
      "is_ai_message": false,
      "status": "delivered"
    }
  ]
}
```

## Implementation Requirements

### Flask Blueprint Structure

```python
# File: routes/ai_chat_route.py
from flask import Blueprint, request, jsonify
from flask_jwt_extended import jwt_required, get_jwt_identity

ai_chat_bp = Blueprint('ai_chat', __name__)

@ai_chat_bp.route('/send', methods=['POST'])
@jwt_required()
def send_ai_message():
    # Implementation here
    pass
```

### Environment Variables Required

```env
MONGODB_URI=mongodb://localhost:27017/letsapp
ENCRYPTION_KEY=<fernet_key_base64>
OPENAI_API_KEY=<fallback_if_needed>
```

### Core Logic Flow

1. **Authentication**: Verify JWT token and extract user_id
2. **Validation**: Validate request data (message, room_id, user_id)
3. **Authorization**: Ensure current_user can access the specified room
4. **API Key Retrieval**: Get encrypted API key from users collection
5. **Decryption**: Decrypt the API key using Fernet
6. **Message Storage**: Store user message in messages collection
7. **OpenAI API Call**: Send message to OpenAI with user's API key
8. **AI Response Storage**: Store AI response in messages collection
9. **Response Formatting**: Return both messages to frontend

### Error Handling Requirements

Handle these specific scenarios:

- Missing or invalid JWT token
- Missing required fields in request
- User not found in database
- No API key configured for user
- API key decryption failure
- OpenAI API authentication errors
- OpenAI API rate limit errors
- OpenAI API service errors
- Database connection/operation failures
- Unexpected exceptions

### Security Requirements

1. **Input Sanitization**: Sanitize all user inputs
2. **Authorization Checks**: Verify user owns the room_id
3. **API Key Protection**: Never log or expose API keys
4. **Error Message Safety**: Don't expose internal system details
5. **Rate Limiting**: Consider implementing per-user rate limits

### MongoDB Operations

```python
# Example operations needed:
users_collection.find_one({'_id': user_id})
messages_collection.insert_one(message_document)
messages_collection.find({'room_id': room_id}).sort('timestamp', 1)
```

### OpenAI Integration

```python
# Expected OpenAI API call pattern:
import openai

openai.api_key = decrypted_user_api_key
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are Leta AI, a helpful assistant."},
        {"role": "user", "content": user_message}
    ],
    max_tokens=500,
    temperature=0.7
)
ai_response = response.choices[0].message.content
```

### Dependencies Required

```txt
flask
flask-jwt-extended
pymongo
cryptography
openai
python-dotenv
```

## Testing Requirements

### Unit Tests

- Test JWT authentication
- Test input validation
- Test API key encryption/decryption
- Test OpenAI API error handling
- Test database operations

### Integration Tests

- Test complete message flow
- Test error scenarios end-to-end
- Test with real OpenAI API (using test key)

### Manual Testing

```bash
# Test with curl:
curl -X POST http://localhost:5001/api/chat/ai/send \
  -H "Authorization: Bearer <jwt_token>" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Hello AI",
    "room_id": "ai_chat_user123",
    "user_id": "user123"
  }'
```

## File Structure Expected

```
server/
├── routes/
│   └── ai_chat_route.py          # Main implementation
├── models/
│   └── ai_chat_models.py         # Data models (optional)
├── utils/
│   └── encryption_utils.py       # Encryption helpers
├── requirements.txt              # Dependencies
└── blueprint_registration.py     # Blueprint registration
```

## Implementation Notes

### Message ID Generation

Use UUID4 for message IDs to avoid collisions:

```python
import uuid
message_id = str(uuid.uuid4())
```

### Timestamp Format

Use ISO format timestamps:

```python
from datetime import datetime
timestamp = datetime.utcnow().isoformat()
```

### Room ID Pattern

AI chat room IDs follow pattern: `ai_chat_{user_id}`

### Logging

Add comprehensive logging for debugging:

```python
import logging
logging.info(f"AI chat request from user {user_id}")
logging.error(f"OpenAI API error: {error}")
```

## Success Criteria

- [ ] Frontend can send messages and receive AI responses
- [ ] All error cases handled gracefully
- [ ] Messages stored correctly in database
- [ ] User API keys remain secure
- [ ] Proper HTTP status codes returned
- [ ] Clean error messages for users
- [ ] No system information leaked in errors
- [ ] Performance acceptable (<3s response time)

## MVP Scope (What NOT to implement yet)

- Real-time socket emissions (future enhancement)
- Message pagination (use existing patterns)
- Multiple AI providers (OpenAI only for MVP)
- Conversation context (single message/response for MVP)
- Admin features or usage analytics
- Caching or performance optimizations

## Integration Points

- Must work with existing JWT authentication system
- Must use existing MongoDB connection patterns
- Must follow existing Flask blueprint architecture
- Must integrate with existing user management system

This prompt provides everything needed to implement a production-ready AI chat backend that integrates seamlessly with the existing LetsApp frontend and infrastructure.
